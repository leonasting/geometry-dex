{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20499e81-c20c-414d-8746-ed490a361693",
   "metadata": {},
   "source": [
    "Pointnet Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb45d4d-6b20-4973-b747-8bb45ee7008e",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cceb8235-0484-4a0c-88d9-b39a4ae35b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import gym   # Environment Simulation\n",
    "import os    # Operation with local space\n",
    "import random# Random Seed generation\n",
    "import wandb # Weight and bias logging\n",
    "import argparse# for setting argument\n",
    "# Deep Neural Network components\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from  torchsummary import summary\n",
    "from torch.utils.data import Dataset\n",
    "# Arrays and Rotations\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "# Local Imports\n",
    "import dex_envs # Custom environemnt\n",
    "#from arguments_pointnet import get_args\n",
    "from models.pointnet import PointNetClsAndPose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0852eda-679c-4a51-81d1-2725025763c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointNetClsAndPose(\n",
      "  (feat_net): PointNetfeatTwoStream(\n",
      "    (feat_net): PointNetfeat(\n",
      "      (conv1): Conv1d(12, 64, kernel_size=(1,), stride=(1,))\n",
      "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (cls_fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (cls_fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (cls_fc3): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (cls_bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (cls_bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (cls_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (rotation_fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (rotation_fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (rotation_fc3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (rotation_bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (rotation_bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (rotation_dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(PointNetClsAndPose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ba5fd06-bb34-4d02-85b4-5e55f3e3ab68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'warn', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# always raise numpy error\n",
    "np.seterr(all='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4451f805-e09e-4660-838c-097871865cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not enable wandb output\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "#os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f29af2d-5bf9-4957-924c-8a668996d437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3cd05a6-d7e7-4124-8b96-44b22cb2304e",
   "metadata": {},
   "source": [
    "Here are the param for the training\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "num_points = 128\n",
    "\n",
    "workers = 128\n",
    "\n",
    "n_epoch = 30\n",
    "\n",
    "expID = 0\n",
    "\n",
    "seed - 125\n",
    "\n",
    "train_name = []# Name of training environments\n",
    "\n",
    "test_name = []# Name of test environments\n",
    "\n",
    "dave_dir = \"dex_logs/\"\n",
    "\n",
    "std_data_aug = 0.00384\n",
    "\n",
    "alpha = 0.459#coefficient for classification and relative rotation estimation\n",
    "\n",
    "no_safe actio=\"store_true\"\n",
    "\n",
    "lr = 0.0004086\n",
    "\n",
    "output_dim = 512 bottleneck dim of Pointnet; claimed to be important by the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbcf0549-5d21-413d-a336-27344beb8040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--batch_size'], dest='batch_size', nargs=None, const=None, default=128, type=<class 'int'>, choices=None, help='input batch size', metavar=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch_size', type=int, default=128, help='input batch size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "497b4f57-3e04-45ce-96e3-adaa82e7b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "725006c8-72e4-41a0-80d1-983d8d1d408e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "argparse.Namespace"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29dd8094-9b7e-4f65-8060-30f2aa492666",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_points = 128\n",
    "args.workers = 128\n",
    "args.n_epoch = 30\n",
    "args.expID = 0\n",
    "args.seed = 125\n",
    "#train_name = []# Name of training environments\n",
    "#test_name = []# Name of test environments\n",
    "args.save_dir = \"dex_logs/\"\n",
    "args.std_data_aug = 0.00384\n",
    "args.alpha = 0.459#coefficient for classification and relative rotation estimation\n",
    "args.no_safe=\"store_true\"\n",
    "args.lr = 0.0004086\n",
    "args.output_dim = 512# bottleneck dim of Pointnet; claimed to be important by the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c98b0c30-bd67-4365-a511-18c8ed175a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "33cd0bda-0e3f-41f2-b3ef-97f813cf946d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1ebdfb7410>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9a996dc6-1185-40f4-8cdd-c6e79006443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = '{}_{:04d}'.format('pointnet', args.expID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a858eb83-fb6b-465b-9146-f575e90770a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pointnet_0000'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e4be4013-e708-4772-8ba3-a6a811f95161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_save_dirs(args):\n",
    "    \"\"\"\n",
    "    To create save directory.\n",
    "    Expects args to have \"save_dir argument\" key\n",
    "    agent_type -hard coded to pointnet\n",
    "    \"\"\"\n",
    "    agent_type = 'pointnet'\n",
    "    # create method directory\n",
    "    args.save_dir = os.path.join(args.save_dir, agent_type)\n",
    "    if not os.path.exists(args.save_dir):\n",
    "        os.makedirs(args.save_dir)\n",
    "    # check for existing log\n",
    "    exp_path = os.path.join(\n",
    "        args.save_dir, '{}_{:04d}'.format(agent_type, args.expID))\n",
    "    if not os.path.exists(exp_path):\n",
    "        os.makedirs(exp_path)\n",
    "    args.save_path = exp_path\n",
    "    print('*' * 40)\n",
    "    print('** starting a new run')\n",
    "    print('*' * 40)\n",
    "def init_wandb(args, run_name):\n",
    "    wandb.init(name=run_name, id=run_name, resume=None,\n",
    "               save_code=True, anonymous=\"allow\")\n",
    "def log_callback(logged_dict):\n",
    "    wandb.log(logged_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "761eb740-2e73-4f5e-bb14-d36f46c38f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "** starting a new run\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "init_wandb(args, run_name)\n",
    "create_save_dirs(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1924c4de-f552-4186-b47e-f0098a8bc6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_cls_pose(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7a7dd130-33e6-4029-be8d-2ba125814e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(pred_class, target):\n",
    "    pred_choice = pred_class.data.max(1)[1]\n",
    "    correct = pred_choice.eq(target.data).cpu().sum()\n",
    "    accuracy = correct.item() / float(args.batch_size)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def arcsine_loss(pred_rotation, rotation):\n",
    "    assert len(pred_rotation.shape) == 2 and pred_rotation.shape[1] == 9\n",
    "    assert len(rotation.shape) == 2 and rotation.shape[1] == 9\n",
    "    frobenius = torch.sqrt(torch.sum((pred_rotation - rotation) ** 2, dim=1))\n",
    "    loss = 2 * \\\n",
    "        torch.arcsin(torch.minimum(torch.ones_like(\n",
    "            frobenius), frobenius / (2 * np.sqrt(2))))\n",
    "    return loss.mean(dim=0)\n",
    "\n",
    "\n",
    "def compute_geodesic_distance_from_two_matrices(m1, m2):\n",
    "    batch = m1.shape[0]\n",
    "    m = torch.bmm(m1, m2.transpose(1, 2))  # batch*3*3\n",
    "    cos = (m[:, 0, 0] + m[:, 1, 1] + m[:, 2, 2] - 1)/2\n",
    "    cos = torch.min(cos, torch.autograd.Variable(torch.ones(batch)))#.cuda()))\n",
    "    cos = torch.max(cos, torch.autograd.Variable(torch.ones(batch))*-1)#.cuda())*-1)\n",
    "    theta = torch.acos(cos)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "378b1260-720a-418e-b634-025f123a3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoStreamDataset(Dataset):\n",
    "    def __init__(self, env_names, num_points=2500, data_aug=True, std_data_aug=0.02, num_data=100000, seed=123):\n",
    "        self.envs = [makeEnv(env_name, 0, args)() for env_name in env_names]\n",
    "        self.num_classes = len(env_names)\n",
    "        for env in self.envs:\n",
    "            env.reset()\n",
    "            assert len(env.sim.model.mesh_vertadr) == 13, '{} meshes found, expecting 13 (env: {})'.format(len(env.sim.model.mesh_vertadr), env)\n",
    "        self.rand = RandomState(seed)\n",
    "        # self.rand = np.random\n",
    "        self.num_points = num_points\n",
    "        self.data_aug = data_aug\n",
    "        self.num_data = num_data\n",
    "        self.std_data_aug = std_data_aug\n",
    "\n",
    "    def _get_points(self, env):\n",
    "        vert_start_adr = env.sim.model.mesh_vertadr[-1]\n",
    "        object_vert = env.sim.model.mesh_vert[vert_start_adr:]\n",
    "        # select some number of object vertices\n",
    "        selected = self.rand.randint(low=0, high=object_vert.shape[0], size=self.num_points)\n",
    "        sampled_points = object_vert[selected].copy()\n",
    "        assert sampled_points.shape[0] == self.num_points and sampled_points.shape[1] == 3\n",
    "        object_normals = env.sim.model.mesh_normal[vert_start_adr:]\n",
    "        sampled_normals = object_normals[selected].copy()\n",
    "        assert sampled_normals.shape[0] == self.num_points and sampled_normals.shape[1] == 3\n",
    "        return sampled_points, sampled_normals\n",
    "\n",
    "    def _normalize(self, point_set):\n",
    "        \"\"\"zero-center and scale to unit sphere\"\"\"\n",
    "        point_set = point_set - np.expand_dims(np.mean(point_set, axis=0), 0)  # center\n",
    "        dist = np.max(np.sqrt(np.sum(point_set ** 2, axis=1)), 0)\n",
    "        point_set = point_set / dist  # scale\n",
    "        return point_set\n",
    "\n",
    "    def _augment(self, point_set):\n",
    "        # random jitter\n",
    "        point_set += self.rand.normal(0,self.std_data_aug, size=point_set.shape)\n",
    "        return point_set\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        target = index % self.num_classes\n",
    "        sampled_points, sampled_normals = self._get_points(\n",
    "            self.envs[target])\n",
    "        # apply random rotation to first point set\n",
    "        first_rotation = R.random()\n",
    "#        point_set1 = np.matmul(sampled_points, first_rotation.as_dcm().T)\n",
    "        point_set1 = np.matmul(sampled_points, first_rotation.as_matrix().T)\n",
    "\n",
    "        # apply random rotation to second point set\n",
    "        second_rotation = R.random()\n",
    "#        point_set2 = np.matmul(sampled_points, second_rotation.as_dcm().T)\n",
    "        point_set2 = np.matmul(sampled_points, second_rotation.as_matrix().T)\n",
    "\n",
    "        # apply same rotations to normals\n",
    "#        normal_set1 = np.matmul(sampled_normals, first_rotation.as_dcm().T)\n",
    "        normal_set1 = np.matmul(sampled_normals, first_rotation.as_matrix().T)\n",
    "\n",
    "        normal_set2 = np.matmul(\n",
    "#            sampled_normals, second_rotation.as_dcm().T)\n",
    "            sampled_normals, second_rotation.as_matrix().T)\n",
    "\n",
    "        # obtain the rotation between two rotated point sets\n",
    "        rotation_diff = np.matmul(\n",
    "#            second_rotation.as_dcm(), first_rotation.inv().as_dcm())\n",
    "            second_rotation.as_matrix(), first_rotation.inv().as_matrix())\n",
    "\n",
    "        rotation_diff = rotation_diff.astype(\n",
    "            np.float32).flatten()  # reformat for training\n",
    "\n",
    "        # zero-center and scale to unit sphere\n",
    "        point_set1 = self._normalize(point_set1)\n",
    "        point_set2 = self._normalize(point_set2)\n",
    "\n",
    "        # data augmentation\n",
    "        if self.data_aug:\n",
    "            point_set1 = self._augment(point_set1)\n",
    "            point_set2 = self._augment(point_set2)\n",
    "\n",
    "        return_set1 = np.concatenate(\n",
    "            [point_set1, normal_set1], axis=-1).astype(np.float32)\n",
    "        return_set2 = np.concatenate(\n",
    "            [point_set2, normal_set2], axis=-1).astype(np.float32)\n",
    "\n",
    "        return return_set1, return_set2, target, rotation_diff\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e02959a3-ac27-4ba9-8108-0cb83586fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#args.train_names = args.train_names if args.train_names else ALL_TRAIN\n",
    "args.train_names=['knife']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a4586019-8472-412e-b34b-a26b42874ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['knife'] 128 0.00384 125\n"
     ]
    }
   ],
   "source": [
    "print(args.train_names, args.num_points, args.std_data_aug, args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3d234d28-44ac-4eae-b1fe-b1625c3d426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeEnv(env_name, idx, args):\n",
    "    \"\"\"return wrapped gym environment for parallel sample collection (vectorized environments)\"\"\"\n",
    "    def helper():\n",
    "        e = gym.make('{}-rotate-v1'.format(env_name))\n",
    "        e.seed(args.seed + idx)\n",
    "        return e\n",
    "    return helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cd1f0ad4-bf5f-4f7d-bd81-8e3ee13c09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TwoStreamDataset(args.train_names, num_points=args.num_points, data_aug=True,std_data_aug=args.std_data_aug, seed=args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "77e09cd6-7f00-4e40-b26d-86ee4a07167d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27203 <class 'numpy.ndarray'> (248, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.envs[0].sim.model.mesh_vertadr[-1],\n",
    "      type(train_dataset.envs[0].sim.model.mesh_vert[train_dataset.envs[0].sim.model.mesh_vertadr[-1]:]),\n",
    "      train_dataset.envs[0].sim.model.mesh_vert[train_dataset.envs[0].sim.model.mesh_vertadr[-1]:].shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3339e4c1-4da3-453a-aa60-a705bcaafffd",
   "metadata": {},
   "source": [
    "home/student/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 128 worker processes in total. Our suggested max number of worker in current system is 36, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
    "  warnings.warn(_create_warning_msg(\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f1481a8d-26d6-4979-bdb5-27d05852b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=int(36),\n",
    "        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "950d9257-11b7-42d6-968b-16fb889059a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1: 217/782] cls loss: 0.000, pose loss: 0.213, loss: 0.115, accuracy: 1.000, geodesic: 0.322\n",
      "[2: 435/782] cls loss: 0.000, pose loss: 0.213, loss: 0.115, accuracy: 1.000, geodesic: 0.319\n",
      "[3: 653/782] cls loss: 0.000, pose loss: 0.203, loss: 0.110, accuracy: 1.000, geodesic: 0.302\n",
      "[5: 89/782] cls loss: 0.000, pose loss: 0.182, loss: 0.098, accuracy: 1.000, geodesic: 0.290\n",
      "[6: 307/782] cls loss: 0.000, pose loss: 0.182, loss: 0.099, accuracy: 1.000, geodesic: 0.254\n",
      "[7: 525/782] cls loss: 0.000, pose loss: 0.188, loss: 0.102, accuracy: 1.000, geodesic: 0.294\n",
      "[8: 743/782] cls loss: 0.000, pose loss: 0.198, loss: 0.107, accuracy: 1.000, geodesic: 0.289\n",
      "[10: 179/782] cls loss: 0.000, pose loss: 0.167, loss: 0.090, accuracy: 1.000, geodesic: 0.269\n",
      "[11: 397/782] cls loss: 0.000, pose loss: 0.170, loss: 0.092, accuracy: 1.000, geodesic: 0.243\n",
      "[12: 615/782] cls loss: 0.000, pose loss: 0.213, loss: 0.115, accuracy: 1.000, geodesic: 0.338\n",
      "[14: 51/782] cls loss: 0.000, pose loss: 0.175, loss: 0.095, accuracy: 1.000, geodesic: 0.295\n",
      "[15: 269/782] cls loss: 0.000, pose loss: 0.181, loss: 0.098, accuracy: 1.000, geodesic: 0.267\n",
      "[16: 487/782] cls loss: 0.000, pose loss: 0.212, loss: 0.115, accuracy: 1.000, geodesic: 0.303\n",
      "[17: 705/782] cls loss: 0.000, pose loss: 0.193, loss: 0.105, accuracy: 1.000, geodesic: 0.257\n",
      "[19: 141/782] cls loss: 0.000, pose loss: 0.176, loss: 0.095, accuracy: 1.000, geodesic: 0.281\n",
      "[20: 359/782] cls loss: 0.000, pose loss: 0.189, loss: 0.102, accuracy: 1.000, geodesic: 0.284\n",
      "[21: 577/782] cls loss: 0.000, pose loss: 0.198, loss: 0.107, accuracy: 1.000, geodesic: 0.271\n",
      "[23: 13/782] cls loss: 0.000, pose loss: 0.213, loss: 0.115, accuracy: 1.000, geodesic: 0.326\n",
      "[24: 231/782] cls loss: 0.000, pose loss: 0.180, loss: 0.097, accuracy: 1.000, geodesic: 0.276\n",
      "[25: 449/782] cls loss: 0.000, pose loss: 0.170, loss: 0.092, accuracy: 1.000, geodesic: 0.296\n",
      "[26: 667/782] cls loss: 0.000, pose loss: 0.194, loss: 0.105, accuracy: 1.000, geodesic: 0.282\n",
      "[28: 103/782] cls loss: 0.000, pose loss: 0.207, loss: 0.112, accuracy: 1.000, geodesic: 0.310\n",
      "[29: 321/782] cls loss: 0.000, pose loss: 0.192, loss: 0.104, accuracy: 1.000, geodesic: 0.324\n"
     ]
    }
   ],
   "source": [
    "model = PointNetClsAndPose(num_classes=len(args.train_names), output_dim=args.output_dim)\n",
    "#model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr, betas=(0.9, 0.999))\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "num_batch = len(train_dataloader)\n",
    "#device = torch.device(\"cuda\")\n",
    "device = torch.device(\"cpu\")\n",
    "count = 0\n",
    "print_count=1000\n",
    "count=0\n",
    "for epoch in range(args.n_epoch):\n",
    "    scheduler.step()\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        logged_dict = dict()\n",
    "        point_set1, point_set2, target, rotation = data\n",
    "        point_set1 = point_set1.to(device, non_blocking=True)\n",
    "        point_set2 = point_set2.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "        rotation = rotation.to(device, non_blocking=True)\n",
    "        # conv implementation needs transpose\n",
    "        point_set1 = point_set1.transpose(2, 1)\n",
    "        point_set2 = point_set2.transpose(2, 1)\n",
    "        optimizer.zero_grad()\n",
    "        pred_class, pred_rotation = model(point_set1, point_set2)\n",
    "        cls_loss = F.nll_loss(pred_class, target)\n",
    "        pose_loss = arcsine_loss(pred_rotation, rotation)\n",
    "        loss = args.alpha * cls_loss + (1 - args.alpha) * pose_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # calculate accuracy\n",
    "        accuracy = get_accuracy(pred_class, target)\n",
    "        geodesic = compute_geodesic_distance_from_two_matrices(\n",
    "            pred_rotation.reshape(-1, 3, 3), rotation.reshape(-1, 3, 3)).mean(axis=0)\n",
    "        \n",
    "        logged_dict['train_cls_loss'] = cls_loss\n",
    "        logged_dict['train_pose_loss'] = pose_loss\n",
    "        logged_dict['train_loss'] = loss\n",
    "        logged_dict['train_accuracy'] = accuracy\n",
    "        logged_dict['train_geodesic'] = geodesic\n",
    "        count+=1\n",
    "        if count%print_count==0:\n",
    "            print('[{}: {}/{}] cls loss: {:.3f}, pose loss: {:.3f}, loss: {:.3f}, accuracy: {:.3f}, geodesic: {:.3f}'.format(\n",
    "                epoch, i, num_batch, cls_loss.item(), pose_loss.item(), loss.item(), accuracy, geodesic))\n",
    "        log_callback(logged_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc37ba17-7eb9-4672-b501-754d0772368a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "249d545c-3627-42d8-be54-3245fb1c25cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '%s/cls_pose_model.pth' %(args.save_path))##save_path added using create save directory function\n",
    "torch.save(model.feat_net.state_dict(),'%s/feat_model.pth' % (args.save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277c58f-07a8-43f9-b28e-289ded72f822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
