{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "327eb8f0-0fce-4a21-804a-6f611bb6db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import wandb\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "import dex_envs\n",
    "from rl_modules.utils import *\n",
    "from rl_modules.ddpg_agent import ddpg_agent\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d362f007-74f3-4ea6-bef7-d5c9c4c29f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "MESH_NAMES=['knife']\n",
    "ALL_TRAIN=['knife']\n",
    "ALL_TEST=['fork']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e97cd6-ab03-4e85-b81a-ef7e0446c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args =parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "683ea27a-6c88-4fb1-bb3e-727786846c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.train_names = []#the environement name\n",
    "args.test_names = []#test_names\n",
    "args.n_cycles = 40000#the times to collect samples per epoch\n",
    "args.n_batches = 4#the times to update the network\n",
    "args.seed = 125\n",
    "args.replay_strategy = \"future\"# the HER strategy\n",
    "args.save_dir = \"dex_logs/\"#the path to save the models\n",
    "args.noise_eps = 0.2#noise eps\n",
    "args.random_eps = 0.3 # random eps\n",
    "args.buffer_size = int(1e6) #the size of the buffer\n",
    "\n",
    "args.replay_k = 4 #ration to be replace\n",
    "args.clip_obs = 200 #the clip ratio\n",
    "args.batch_size= 256# the sample batch size\n",
    "args.gamma =0.98 #the discount factor\n",
    "args.action_l2 = 1#l2 reg\n",
    "args.lr_actor = 0.001281 #the learning rate of the actor\n",
    "args.lr_critic = 0.000884\n",
    "args.polyak = 0.95 #the average coefficient\n",
    "args.n_test_rollouts = 2 # the number of tests\n",
    "args.clip_range = 5 # the clip ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "febbe1cf-95a9-4e18-b26b-9788aa5e9f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nparser.add_argument(\\'--no_cuda\\', action=\\'store_true\\',\\n                        help=\\'if use gpu do the acceleration\\')\\nparser.add_argument(\\'--serial\\', action=\"store_true\",\\n                        help=\"do not use multiprocessing\")\\nparser.add_argument(\\'--no_save\\', action=\"store_true\",\\n                        help=\"do not save anything\")\\nparser.add_argument(\\'--eval\\', action=\"store_true\",\\n                        help=\"only eval the network once\")\\nparser.add_argument(\\'--finetune_pointnet\\', action=\"store_true\",\\n                    help=\"allow finetuning in dagger training\")\\nparser.add_argument(\\'--fresh\\', action=\"store_true\",\\n                    help=\"ignore saved checkpoint; start from scratch\")\\nparser.add_argument(\\'--no_save_buffer\\', action=\"store_true\",\\n                    help=\"do not save buffer when saving general checkpoint (to avoid memory error if buffer is too big)\")\\nparser.add_argument(\\'--point_cloud\\', action=\"store_true\",\\n                    help=\"enable using pointnet + MLP\")\\n\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "parser.add_argument('--no_cuda', action='store_true',\n",
    "                        help='if use gpu do the acceleration')\n",
    "parser.add_argument('--serial', action=\"store_true\",\n",
    "                        help=\"do not use multiprocessing\")\n",
    "parser.add_argument('--no_save', action=\"store_true\",\n",
    "                        help=\"do not save anything\")\n",
    "parser.add_argument('--eval', action=\"store_true\",\n",
    "                        help=\"only eval the network once\")\n",
    "parser.add_argument('--finetune_pointnet', action=\"store_true\",\n",
    "                    help=\"allow finetuning in dagger training\")\n",
    "parser.add_argument('--fresh', action=\"store_true\",\n",
    "                    help=\"ignore saved checkpoint; start from scratch\")\n",
    "parser.add_argument('--no_save_buffer', action=\"store_true\",\n",
    "                    help=\"do not save buffer when saving general checkpoint (to avoid memory error if buffer is too big)\")\n",
    "parser.add_argument('--point_cloud', action=\"store_true\",\n",
    "                    help=\"enable using pointnet + MLP\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84474c68-13f0-426d-ab4e-0797c4516d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.no_cuda = True\n",
    "args.serial = True\n",
    "args.no_save = False\n",
    "args.finetune_pointnet = False\n",
    "args.fresh = True\n",
    "args.no_save_buffer =False\n",
    "args.point_cloud = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ae04a44-c01d-438d-aa56-133df6fabb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_rollouts = 1 #the rollout per cycle\n",
    "args.expID = 0\n",
    "args.eval_freq = 50 #number of cycles between eval and logging\n",
    "args.video_count = 1 # number of videos to record during the logging\n",
    "args.load_path = None# expid to load path\n",
    "args.pointnet_load_path = 0\n",
    "args.epoch_per_cycle = 22.966#alternative way to specify n_batches ;\n",
    "#it means the number of epochs to train over the size of the neewly collected data; \n",
    "#if newly collected 1000 transitions,10epochs means training for 100 batches\n",
    "#with batch size being 100\n",
    "args.num_parallel_envs=1#number of parallel VecEnv; if not specified, calculate from the available vCPUs')\n",
    "args.chunk_size=10#if not equal 0, use SubprocChunkVecEnv as proposed in baselines PR 620 with given chunk size')\n",
    "args.load_cycle=None#the cycle index of the loaded eval checkpoint')\n",
    "args.layers=4\n",
    "args.width=768\n",
    "args.num_points = 128#number of points to sample in mujoco\")\n",
    "args.pointnet_output_dim = 512#output dim of the two stream pointnet feature net\")\n",
    "args.eval=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21c4b150-11f2-4f1f-b977-66bbd9d25c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7c0d400-a9d1-4fa1-9313-f22bd253ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** overwriting n_batches from 4 to 8 ***\n"
     ]
    }
   ],
   "source": [
    "args.train_names = args.train_names if args.train_names else ALL_TRAIN\n",
    "args.test_names = args.test_names if args.test_names else ALL_TEST\n",
    "assert len(list(set(args.train_names) & set(args.test_names))) == 0, 'cannot have overlapping train/test envs'\n",
    "\n",
    "# if using eval mode, do not start new training and do not save\n",
    "if args.eval:\n",
    "    args.fresh = False\n",
    "    args.no_save = True\n",
    "\n",
    "# alternative way to specify how many batches to update per cycle\n",
    "if args.epoch_per_cycle:\n",
    "    batches_per_epoch = (args.num_rollouts * 100) / args.batch_size\n",
    "    batches_total = int(batches_per_epoch * args.epoch_per_cycle)\n",
    "    print('*** overwriting n_batches from {} to {} ***'.format(args.n_batches, batches_total))\n",
    "    args.n_batches = batches_total\n",
    "\n",
    "# cap buffer size at 10M\n",
    "total_buffer_size = len(args.train_names) * args.buffer_size\n",
    "if total_buffer_size > int(1e7):\n",
    "    args.buffer_size = int(1e7) // len(args.train_names)\n",
    "    print('adjusted total buffer size from {:.4e} to 1e7'.format(\n",
    "        total_buffer_size))\n",
    "\n",
    "# require parallization args align with each other\n",
    "if args.n_cycles > 0 or args.eval:\n",
    "    if len(args.train_names) > 0:\n",
    "        assert args.num_parallel_envs % (len(\n",
    "            args.train_names)) == 0, 'num_parallel_envs must be multiple of num of train envs ({})'.format(len(args.train_names))\n",
    "        assert args.num_rollouts % args.num_parallel_envs == 0, 'num_rollouts must be multiple of parallel env number ({})'.format(\n",
    "            args.num_parallel_envs)\n",
    "\n",
    "    assert args.n_test_rollouts % (len(args.train_names + args.test_names)) == 0, 'n_test_rollouts must be multiple of num of train envs + test_envs ({} + {} = {})'.format(\n",
    "        len(args.train_names), len(args.test_names), len(args.train_names + args.test_names))\n",
    "    # make sure n_batches must be multiple of num of train envs\n",
    "    if len(args.train_names) > 0:\n",
    "        if args.epoch_per_cycle:\n",
    "            args.n_batches = (\n",
    "                args.n_batches // len(args.train_names)) * len(args.train_names)\n",
    "        else:\n",
    "            assert args.n_batches % len(\n",
    "                args.train_names) == 0, 'n_batches must be multiple of num of train envs ({})'.format(len(args.train_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfbf2da5-61d6-469f-943e-be5622c6808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_callback(args, prefix):\n",
    "    if not args.eval and not args.fresh:\n",
    "        resume_mode = 'allow'\n",
    "    else:\n",
    "        resume_mode = None\n",
    "    run_name = '{}_{:04d}'.format(prefix, args.expID)\n",
    "    wandb.init(name=run_name, id=run_name, resume=resume_mode,\n",
    "               save_code=True, anonymous=\"allow\")\n",
    "    wandb.config.update(args, allow_val_change=True)\n",
    "\n",
    "\n",
    "def log_callback(log_dict):\n",
    "    wandb.log(log_dict)\n",
    "\n",
    "\n",
    "def get_env_params(env, args):\n",
    "    obs = env.reset()\n",
    "    # close the environment\n",
    "    params = {'goal': obs['desired_goal'].shape[-1],\n",
    "              'action': env.action_space.shape[-1],\n",
    "              'action_max': env.action_space.high[-1],\n",
    "              'max_timesteps': env._max_episode_steps,\n",
    "              'obs_to_normalize': obs['minimal_obs'].shape[-1]\n",
    "              }\n",
    "    if args.point_cloud:\n",
    "        params['obs'] = obs['pc_obs'].shape[-1]\n",
    "    else:\n",
    "        params['obs'] = params['obs_to_normalize']\n",
    "    return params\n",
    "\n",
    "\n",
    "def get_policy_params(env, args):\n",
    "    obs = env.reset()\n",
    "    params = dict(state_dim=obs['minimal_obs'].shape[-1] + obs['desired_goal'].shape[-1],\n",
    "                  action_dim=env.action_space.shape[-1],\n",
    "                  max_action=env.action_space.high[-1],\n",
    "                  args=args)\n",
    "    return params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82f3b3a1-cdff-4d77-bc05-30ffa0b9e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "init_callback=init_callback\n",
    "log_callback=log_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06f07c1c-5056-4f1f-91fb-82629522ea0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(action_l2=1, batch_size=256, buffer_size=1000000, chunk_size=10, clip_obs=200, clip_range=5, epoch_per_cycle=22.966, eval=False, eval_freq=50, expID=0, finetune_pointnet=False, fresh=True, gamma=0.98, layers=4, load_cycle=None, load_path=None, lr_actor=0.001281, lr_critic=0.000884, n_batches=8, n_cycles=40000, n_test_rollouts=2, no_cuda=True, no_save=False, no_save_buffer=False, noise_eps=0.2, num_parallel_envs=1, num_points=128, num_rollouts=1, point_cloud=True, pointnet_load_path=0, pointnet_output_dim=512, polyak=0.95, random_eps=0.3, replay_k=4, replay_strategy='future', save_dir='dex_logs/', seed=125, serial=True, test_names=['fork'], train_names=['knife'], video_count=1, width=768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ffa19a2-d9bb-4260-859b-c8190b0ffdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_env = makeEnv((args.train_names + args.test_names)[0], 0, args)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "368f0271-4713-4d16-ae5d-42a88d6aef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#args = get_args()\n",
    "    # create dummy env for accessing spaces attr\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if args.no_cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "# get the environment parameters\n",
    "# assume all envs high-level attributes are the same, use arbitrary one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a30fe41-d09e-4c5b-81ee-c37089c181f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** creating 1 training vec env.. created (time taken: 0.10 s)! **\n",
      "\n",
      "** creating 2 eval vec env.. created (time taken: 0.18 s)! **\n",
      "\n",
      "****************************************\n",
      "** starting a new run\n",
      "****************************************\n",
      "*** successfully loaded pointnet feature model ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== [EXP0000:C000] success %: 0.000, reward: -100.00, dist: 0.711, env time: 2.80 s across 1 episodes\n"
     ]
    }
   ],
   "source": [
    "env_params = get_env_params(dummy_env, args)\n",
    "# assume all envs high-level attributes are the same, use arbitrary one\n",
    "policy_params = get_policy_params(dummy_env, args)\n",
    "# create the ddpg agent to interact with the environment\n",
    "trainer = ddpg_agent(args, dummy_env, env_params, policy_params)\n",
    "init_callback(args=args, prefix=trainer.agent_type)\n",
    "\n",
    "if args.eval:\n",
    "    trainer.eval(log_callback=log_callback)\n",
    "else:\n",
    "    trainer.learn(log_callback=log_callback)\n",
    "\n",
    "dummy_env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e5940b-c536-46bc-bd06-d342aea771e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a08f2ab-b8a5-40c1-bb75-d32eff93b609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5c8341-26d1-4d8f-a959-22a1c5fe50bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6442cb-62b4-4248-a4a7-250e2059873b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c993014-1d16-4d16-a000-0e9da48a97ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723a4c97-beab-4d72-b733-c5aaa5565853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
